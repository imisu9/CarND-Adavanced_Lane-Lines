{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "[//]: # (Image References)\n",
    "\n",
    "[image1]: ./examples/undistort_output.png \"Undistorted\"\n",
    "[image2]: ./test_images/test1.jpg \"Road Transformed\"\n",
    "[image3]: ./examples/binary_combo_example.jpg \"Binary Example\"\n",
    "[image4]: ./examples/warped_straight_lines.jpg \"Warp Example\"\n",
    "[image5]: ./examples/color_fit_lines.jpg \"Fit Visual\"\n",
    "[image6]: ./examples/example_output.jpg \"Output\"\n",
    "[image7]: ./output_images/test1.jpg \"Undistored Image\"\n",
    "[video1]: ./project_video.mp4 \"Video\"\n",
    "\n",
    "## [Rubric](https://review.udacity.com/#!/rubrics/571/view) Points\n",
    "\n",
    "### Here I will consider the rubric points individually and describe how I addressed each point in my implementation.  \n",
    "\n",
    "---\n",
    "\n",
    "### Writeup / README\n",
    "\n",
    "#### 1. Provide a Writeup / README that includes all the rubric points and how you addressed each one.  You can submit your writeup as markdown or pdf.  [Here](https://github.com/udacity/CarND-Advanced-Lane-Lines/blob/master/writeup_template.md) is a template writeup for this project you can use as a guide and a starting point.  \n",
    "\n",
    "You're reading it!\n",
    "\n",
    "### Camera Calibration\n",
    "\n",
    "#### 1. Briefly state how you computed the camera matrix and distortion coefficients. Provide an example of a distortion corrected calibration image.\n",
    "\n",
    "The code for this step is contained in the first code cell of the IPython notebook located in \"./examples/example.ipynb\" (or in lines # through # of the file called `some_file.py`).  \n",
    "\n",
    "I start by preparing \"object points\", which will be the (x, y, z) coordinates of the chessboard corners in the world. Here I am assuming the chessboard is fixed on the (x, y) plane at z=0, such that the object points are the same for each calibration image.  Thus, `objp` is just a replicated array of coordinates, and `objpoints` will be appended with a copy of it every time I successfully detect all chessboard corners in a test image.  `imgpoints` will be appended with the (x, y) pixel position of each of the corners in the image plane with each successful chessboard detection.  \n",
    "\n",
    "I then used the output `objpoints` and `imgpoints` to compute the camera calibration and distortion coefficients using the `cv2.calibrateCamera()` function.  I applied this distortion correction to the test image using the `cv2.undistort()` function and obtained this result: \n",
    "\n",
    "![alt text][image1]\n",
    "\n",
    "I've used `cv2.getPerspectiveTransform()` to get M, the transform matrix. Afterwards, I finally used `cv2.warpPerspective()` to warp your image to a top-down view, whcih was not strictly required at this moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "#%matplotlib qt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of inside corners in x & y\n",
    "nx = 9\n",
    "ny = 6\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(7,5,0)\n",
    "objp = np.zeros((ny*nx,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('./camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None)\n",
    "    \n",
    "    # If found, add object points, image points (after refining the them)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        corners_refined_loc = cv2.cornerSubPix(gray, corners, (11,11), (-1,-1), criteria)\n",
    "        imgpoints.append(corners_refined_loc)\n",
    "        \n",
    "        # Calculate camera matrix and distortion coefficients\n",
    "        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "        # Obtain undistored & warped image and matrix\n",
    "        # 1) Undistort using mtx and dist\n",
    "        undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "        # 2) Convert to grayscale\n",
    "        gray2 = cv2.cvtColor(undist, cv2.COLOR_BGR2GRAY)\n",
    "        # 3) Find the chessboard corners\n",
    "        ret2, corners2 = cv2.findChessboardCorners(gray2, (nx, ny), None)\n",
    "        # 4) If corners found: \n",
    "        if ret2 == True:\n",
    "            # a) draw corners\n",
    "            cv2.drawChessboardCorners(undist, (nx, ny), corners2, ret2)\n",
    "            # b) define 4 source points src = np.float32([[,],[,],[,],[,]])\n",
    "            #Note: you could pick any four of the detected corners \n",
    "            # as long as those four corners define a rectangle\n",
    "            #One especially smart way to do this would be to use four well-chosen\n",
    "            # corners that were automatically detected during the undistortion steps\n",
    "            #We recommend using the automatic detection of corners in your code\n",
    "            offset = 100\n",
    "            img_size = (gray2.shape[1], gray2.shape[0])\n",
    "            src = np.float32([corners2[0], corners2[nx-1], corners2[-1], corners2[-nx]])\n",
    "            # c) define 4 destination points dst = np.float32([[,],[,],[,],[,]])\n",
    "            dst = np.float32([[offset, offset], [img_size[0]-offset, offset], [img_size[0]-offset, img_size[1]-offset], [offset, img_size[1]-offset]])\n",
    "            # d) use cv2.getPerspectiveTransform() to get M, the transform matrix\n",
    "            M = cv2.getPerspectiveTransform(src, dst)\n",
    "            # e) use cv2.warpPerspective() to warp your image to a top-down view\n",
    "            warped = cv2.warpPerspective(undist, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "            # Draw images\n",
    "            f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "            f.tight_layout()\n",
    "            ax1.imshow(img)\n",
    "            ax1.set_title('Original Image: '+fname.split('/')[-1], fontsize=50)\n",
    "            ax2.imshow(warped)\n",
    "            ax2.set_title('Undistorted and Warped Image', fontsize=50)\n",
    "            plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "            \n",
    "            # Save undistored & warped images to ./output_images\n",
    "            fname2 = './output_images/' + fname.split('/')[-1]\n",
    "            cv2.imwrite(fname2, warped)\n",
    "            #plt.imsave(fname2, warped)\n",
    "        else:\n",
    "            print(fname, \": corners NOT found in the undistored image\")\n",
    "    else:\n",
    "        print(fname, \": corners NOT found in the original image.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline (single images)\n",
    "\n",
    "#### 1. Provide an example of a distortion-corrected image.\n",
    "\n",
    "To demonstrate this step, I will describe how I apply the distortion correction to one of the test images like this one:\n",
    "\n",
    "[//]: # (Image References)\n",
    "\n",
    "[image7]: ./output_images/test1.jpg \"Undistored Image\"\n",
    "\n",
    "![alt text][image7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''\n",
    "Utilize pre-calculated camera matrix and distortion coefficients\n",
    "to obtain distortion-corrected images from test images at './test_images/test*.jpg'\n",
    "'''\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('./test_images/test*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    \n",
    "    # Obtain undistored & warped image and matrix\n",
    "    # Undistort using mtx and dist\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    # Draw images\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image: '+fname.split('/')[-1], fontsize=50)\n",
    "    ax2.imshow(undist)\n",
    "    ax2.set_title('Undistorted Image', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "    # Save undistored & warped images to ./output_images\n",
    "    fname2 = './output_images/' + 'undistorted_' + fname.split('/')[-1]\n",
    "    cv2.imwrite(fname2, undist)\n",
    "    #plt.imsave(fname2, undist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Describe how (and identify where in your code) you used color transforms, gradients or other methods to create a thresholded binary image.  Provide an example of a binary image result.\n",
    "\n",
    "pipeline()  function performs 6 jobs:\n",
    "1. Convert to HLS color space instead of grayscale which lost color information for the lane lines.\n",
    "2. Apply Sobel x to take derivative in x\n",
    "3. Threshold x gradient\n",
    "4. Threshold color channel\n",
    "5. Stack each channel to view their individual contributions in green and blue respectively.\n",
    "6. Combine the two binary thresholds\n",
    "\n",
    "[//]: # (Image References)\n",
    "\n",
    "[image3]: ./output_images/color_binary_test1.jpg \"Color Binary Example\"\n",
    "[image4]: ./output_images/combined_binary_test1.jpg \"Combined Binary Example\"\n",
    "\n",
    "![alt text][image3]\n",
    "![alt text][image4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_img(img, s_thresh=(170, 255), sx_thresh=(20, 100)):\n",
    "    '''\n",
    "    img is the undistorted image\n",
    "    '''\n",
    "    # 1. Convert to HLS color space and separate the L & S channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    # 2. Sobel x\n",
    "    # Take the derivative in x\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0)\n",
    "    # Absolute x derivative to accentuate lines away from horizontal\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # 3. Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= s_thresh[1])] = 1\n",
    "    \n",
    "    # 4. Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    \n",
    "    # 5. Stack each channel to view their individual contribution in green and blue respectively\n",
    "    # This returns a stack of the two binary images, whose components you can see as different colors.\n",
    "    color_binary = np.dstack((np.zeros_like(sxbinary), sxbinary, s_binary)) * 255\n",
    "    \n",
    "    # 6. Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[(s_binary ==1) | (sxbinary == 1)] = 1\n",
    "    \n",
    "    return color_binary, combined_binary\n",
    "\n",
    "'''\n",
    "Apply pipeline() to undistored images of ./output_images/test*.jpg.\n",
    "'''\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('./output_images/undistorted_test*.jpg')\n",
    "\n",
    "# Step through the list of undistorted images\n",
    "for fname in images:\n",
    "    # Read in undistorted image\n",
    "    img = cv2.imread(fname)\n",
    "    \n",
    "    # Obtain color_binary & combined_binary\n",
    "    color_binary, combined_binary = binary_img(img)\n",
    "    # Draw images\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(color_binary)\n",
    "    ax1.set_title('Color binary Image: '+fname.split('/')[-1], fontsize=50)\n",
    "    ax2.imshow(combined_binary)\n",
    "    ax2.set_title('Combined binary Image', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "    # Save color_binary & combined_binary images to ./output_images\n",
    "    fname2 = './output_images/' + 'color_binary_' + fname.split('/')[-1]\n",
    "    #cv2.imwrite(fname2, color_binary)\n",
    "    plt.imsave(fname2, color_binary)\n",
    "    \n",
    "    fname3 = './output_images/' + 'combined_binary_' + fname.split('/')[-1]\n",
    "    #cv2.imwrite(fname3, combined_binary)\n",
    "    plt.imsave(fname3, combined_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Describe how (and identify where in your code) you performed a perspective transform and provide an example of a transformed image.\n",
    "\n",
    "The code for my perspective transform includes a function called `warper()`.  The `warper()` function takes as inputs an image (`img`) and calculates source (`src`) and destination (`dst`) points.  I chose the hardcode the source and destination points in the following manner:\n",
    "\n",
    "```python\n",
    "src = np.float32(\n",
    "    [[(img_size[0] / 2) - 55, img_size[1] / 2 + 100],\n",
    "    [((img_size[0] / 6) - 10), img_size[1]],\n",
    "    [(img_size[0] * 5 / 6) + 60, img_size[1]],\n",
    "    [(img_size[0] / 2 + 55), img_size[1] / 2 + 100]])\n",
    "dst = np.float32(\n",
    "    [[(img_size[0] / 4), 0],\n",
    "    [(img_size[0] / 4), img_size[1]],\n",
    "    [(img_size[0] * 3 / 4), img_size[1]],\n",
    "    [(img_size[0] * 3 / 4), 0]])\n",
    "```\n",
    "\n",
    "This resulted in the following source and destination points:\n",
    "\n",
    "| Source        | Destination   | \n",
    "|:-------------:|:-------------:| \n",
    "| 585, 460      | 320, 0        | \n",
    "| 203, 720      | 320, 720      |\n",
    "| 1127, 720     | 960, 720      |\n",
    "| 695, 460      | 960, 0        |\n",
    "\n",
    "I verified that my perspective transform was working as expected by drawing the `src` and `dst` points onto a test image and its warped counterpart to verify that the lines appear parallel in the warped image.\n",
    "\n",
    "[image]: ./output_images/warped_test1.jpg \"Wapred Image\"\n",
    "\n",
    "![alt text][image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warper(img):\n",
    "    '''\n",
    "    img is undistroted image\n",
    "    '''\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "        \n",
    "    # Define 4 source points src = np.float32([[,],[,],[,],[,]])\n",
    "    src = np.float32([[(img_size[0] / 2) - 55, img_size[1] / 2 + 100],\n",
    "                                  [((img_size[0] / 6) - 10), img_size[1]],\n",
    "                                  [(img_size[0] * 5 / 6) + 60, img_size[1]],\n",
    "                                  [(img_size[0] / 2 + 55), img_size[1] / 2 + 100]])\n",
    "    # Define 4 destination points dst = np.float32([[,],[,],[,],[,]])\n",
    "    dst = np.float32([[(img_size[0] / 4), 0],\n",
    "                                  [(img_size[0] / 4), img_size[1]],\n",
    "                                  [(img_size[0] * 3 / 4), img_size[1]],\n",
    "                                  [(img_size[0] * 3 / 4), 0]])\n",
    "    # Use cv2.getPerspectiveTransform() to get M, the transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    # Use cv2.getPerspectiveTransform() to get Minv, the inverse transform matrix\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    # Use cv2.warpPerspective() to warp your image to a top-down view\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return warped, M, Minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''\n",
    "Utilize warper() fucntion\n",
    "to obtain perspective-transformed, warped images from test images at './test_images/test*.jpg'\n",
    "'''\n",
    "# Make a list of calibration images\n",
    "#images = glob.glob('./test_images/test*.jpg')\n",
    "images = glob.glob('./output_images/undistorted_test*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    \n",
    "    # Call warper() to obtained perspective-transformed, warped image\n",
    "    warped, M, Minv = warper(img)\n",
    "    \n",
    "    # Draw images\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image: '+fname.split('/')[-1], fontsize=50)\n",
    "    ax2.imshow(warped)\n",
    "    ax2.set_title('Warped Image', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "    # Save warped images to ./output_images\n",
    "    fname2 = './output_images/' + 'warped_' + fname.split('/')[-1]\n",
    "    cv2.imwrite(fname2, warped)\n",
    "    #plt.imsave(fname2, undist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Describe how (and identify where in your code) you identified lane-line pixels and fit their positions with a polynomial?\n",
    "\n",
    "I used sliding window method in `find_lane_pixels()` to find lane pixels from warped combined binary images. Afterwards, I fit my lane lines with a 2nd order polynomial using `np.polyfit` in `fit_polynomial()`. Once I've checked the lane with sliding window technique, with the known polynomial fit values, I implemented `fit_poly()` function assuming line location does not deviated far off frame by frame.\n",
    "\n",
    "[//]: # (Image References)\n",
    "\n",
    "[image4]: ./output_images/combined_bin_lane_polyfit_test6.jpg \"Combined binary polynomial fit\"\n",
    "\n",
    "![alt text][image4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Hyperparameters\n",
    "'''\n",
    "# Choose the number of sliding windows\n",
    "nwindows = 9\n",
    "# Set the width of the windows +/- margin\n",
    "margin = 100\n",
    "# Set minimum number of pixels found to recenter windows\n",
    "minpix = 50\n",
    "\n",
    "# Polynomial fit values from the previous frame\n",
    "# Make sure to grab the actual values from the previous step in your project!\n",
    "#left_fit = np.array([ 2.13935315e-04, -3.77507980e-01,  4.76902175e+02])\n",
    "#right_fit = np.array([4.17622148e-04, -4.93848953e-01,  1.11806170e+03])\n",
    "left_fit = np.array([0, 0, 0])\n",
    "right_fit = np.array([0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lane_pixels(binary_warped):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    #print(\"binary_warped.shape: \", binary_warped.shape)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    #print(\"histogram.shape: \", histogram.shape)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        # Find the four below boundaries of the window\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low), (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low), (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        # Identify the nonzero in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        #print(\"good_right_inds: \", good_right_inds)\n",
    "        #print(\"good_right_inds.shape: \", good_right_inds.shape)\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If > minpix pixels, recenter next window\n",
    "        # ('right' or 'leftx_current') on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_polynomial(binary_warped):\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "\n",
    "    # Fit a second order polynomial to each using 'np.polyfit'\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "\n",
    "    return left_fit, right_fit, out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_poly(img_shape, leftx, lefty, rightx, righty):\n",
    "    # Fit a second order polynomial to each with np.polyfit()\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "    # Calc both polynomials using ploty, left_fit and right_fit\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    return left_fitx, right_fitx, ploty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_around_poly(binary_warped):\n",
    "    # Grab activated pixels\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    ### Set the area of search based on activated x-values ###\n",
    "    ### within the +/- margin of our polynomial function ###\n",
    "    ### Hint: consider the window areas for the similarly named variables ###\n",
    "    ### in the previous quiz, but change the windows to our new search area ###\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "                    left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "                    left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "                    right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "                    right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Fit new polynomials\n",
    "    left_fitx, right_fitx, ploty = fit_poly(binary_warped.shape, leftx, lefty, rightx, righty)\n",
    "    \n",
    "    ## Visualization ##\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    \n",
    "    # Plot the polynomial lines onto the image\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    ## End visualization steps ##\n",
    "    \n",
    "    return result, left_fitx, right_fitx, ploty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''\n",
    "Utilize find_lane_pixels() and fit_polynomial() functions\n",
    "to find and fit polynomials on the lane\n",
    "'''\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('./test_images/test*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    \n",
    "    # Obtain undistored & warped image and matrix\n",
    "    # Undistort using mtx and dist\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    # Obtain color_binary & combined_binary\n",
    "    color_binary, combined_binary = binary_img(undist)\n",
    "    # Warpe binary images\n",
    "    #warped_color_binary = warper(color_binary)\n",
    "    warped_combined_binary, M, Minv = warper(combined_binary)\n",
    "    # Fit polynomials on lanes\n",
    "    #lane_poly_color = fit_polynomial(warped_color_binary)\n",
    "    left_fit, right_fit, lane_poly_combined = fit_polynomial(warped_combined_binary)\n",
    "    lane_poly_combined, left_fitx, right_fitx, ploty = search_around_poly(warped_combined_binary)\n",
    "    \n",
    "    # Draw images\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(warped_combined_binary)\n",
    "    ax1.set_title('Warped combined binary, ' + fname.split('/')[-1], fontsize=50)\n",
    "    ax2.imshow(lane_poly_combined)\n",
    "    ax2.set_title('Combined binary lane poly', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "    # Save images to ./output_images\n",
    "    #fname2 = './output_images/' + 'color_bin_lane_polyfit_' + fname.split('/')[-1]\n",
    "    #cv2.imwrite(fname2, lane_poly_color)\n",
    "    #plt.imsave(fname2, lane_poly_color)\n",
    "    fname3 = './output_images/' + 'combined_bin_lane_polyfit_' + fname.split('/')[-1]\n",
    "    #cv2.imwrite(fname3, lane_poly_combined)\n",
    "    plt.imsave(fname3, lane_poly_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Describe how (and identify where in your code) you calculated the radius of curvature of the lane and the position of the vehicle with respect to center.\n",
    "\n",
    "I took the meter per pixel ratio and implementation  from the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Hyperparameters\n",
    "'''\n",
    "# Define conversions in x and y from pixels space to meters\n",
    "# meters per pixel in y dimension\n",
    "ym_per_pix = 30/720\n",
    "# meters per pixel in x dimension\n",
    "xm_per_pix = 3.7/700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_curvature_real(ploty, left_fitx, right_fitx):\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in meters.\n",
    "    '''\n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)*ym_per_pix\n",
    "    \n",
    "    # Fit a second order polynomial to pixel positions in each lane line\n",
    "    # Fit new polynomials to x, y in world space\n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, left_fitx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, right_fitx*xm_per_pix, 2)\n",
    "    \n",
    "    # Calculation of R_curve (radius of curvature)\n",
    "    left_curverad = ((1+ (2*left_fit_cr[0]*y_eval + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + 2*(right_fit_cr[0]*y_eval + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    # Assume the car is at the center of the image\n",
    "    dist_center = ((right_fitx[0]-left_fitx[0])/2 + left_fitx[0]) - img.shape[1]/2\n",
    "    dist_center *= xm_per_pix\n",
    "    \n",
    "    return left_curverad, right_curverad, dist_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the radius of curvature in meters for both lane lines\n",
    "left_curverad, right_curverad, dist_center = measure_curvature_real(ploty, left_fitx, right_fitx)\n",
    "print(left_curverad, 'm', right_curverad, 'm')\n",
    "print(\"The distance from center fo lane: \", dist_center, 'm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Provide an example image of your result plotted back down onto the road such that the lane area is identified clearly.\n",
    "\n",
    "Here is an example of my result on a test image:\n",
    "\n",
    "[//]: # (Image References)\n",
    "\n",
    "[image6]: ./output_images/lane_clarified_test1.jpg \"Lane area clarified\"\n",
    "\n",
    "![alt text][image6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_lane_area(undist, binary_warped, Minv):\n",
    "    # Grab activated pixels\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    ### Set the area of search based on activated x-values ###\n",
    "    ### within the +/- margin of our polynomial function ###\n",
    "    ### Hint: consider the window areas for the similarly named variables ###\n",
    "    ### in the previous quiz, but change the windows to our new search area ###\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "                    left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "                    left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "                    right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "                    right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Fit new polynomials\n",
    "    left_fitx, right_fitx, ploty = fit_poly(binary_warped.shape, leftx, lefty, rightx, righty)\n",
    "    \n",
    "    ## Visualization ##\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    warped = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    window_img = np.zeros_like(warped)\n",
    "    \n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_pts = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    right_line_pts = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    # Combine points from left and right\n",
    "    pts = np.hstack((left_line_pts, right_line_pts))\n",
    "    # Draw the lane onto the warped blank image with differently colored edge lines\n",
    "    cv2.fillPoly(window_img, np.int_([pts]), (0,255, 0))\n",
    "    cv2.polylines(window_img, np.int32([left_line_pts]), isClosed=False, color=(255,0,0), thickness=15)\n",
    "    cv2.polylines(window_img, np.int32([right_line_pts]), isClosed=False, color=(0,0,255), thickness=15)\n",
    "    # Combine area with differently colored edge lines\n",
    "    combined = cv2.addWeighted(warped, 1, window_img, 0.5, 0)\n",
    "    # Warp combined image to original image space using inverse perspective matrix (Minv)\n",
    "    warped = cv2.warpPerspective(combined, Minv, (binary_warped.shape[1], binary_warped.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    # Combine warped image onto undistorted image\n",
    "    result = cv2.addWeighted(undist, 1, warped, 0.5, 0)\n",
    "    \n",
    "    # Calculate the radius of curvature in meters for both lane lines\n",
    "    left_curverad, right_curverad, dist_center = measure_curvature_real(ploty, left_fitx, right_fitx)\n",
    "    # Put texts on the image\n",
    "    text = 'Left curve radius: ' + '{:04.2f}'.format(left_curverad) + 'm'\n",
    "    cv2.putText(result, text, (40,70), cv2.FONT_HERSHEY_PLAIN, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "    text = 'Right curve radius: ' + '{:04.2f}'.format(right_curverad) + 'm'\n",
    "    cv2.putText(result, text, (40,110), cv2.FONT_HERSHEY_PLAIN, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "    text = 'Distance from center: ' + '{:04.2f}'.format(dist_center) + 'm'\n",
    "    cv2.putText(result, text, (40,150), cv2.FONT_HERSHEY_PLAIN, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    # Plot the polynomial lines onto the image\n",
    "    #plt.plot(left_fitx, ploty, color='yellow')\n",
    "    #plt.plot(right_fitx, ploty, color='yellow')\n",
    "    ## End visualization steps ##\n",
    "    \n",
    "    return result, left_fitx, right_fitx, ploty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''\n",
    "Utilize color_lane_area() functions\n",
    "to find and fit polynomials on the lane\n",
    "'''\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('./test_images/test*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    \n",
    "    # Obtain undistored & warped image and matrix\n",
    "    # Undistort using mtx and dist\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    # Obtain color_binary & combined_binary\n",
    "    color_binary, combined_binary = binary_img(undist)\n",
    "    # Warpe binary images\n",
    "    #warped_color_binary = warper(color_binary)\n",
    "    warped_combined_binary, M, Minv = warper(combined_binary)\n",
    "    # Fit polynomials on lanes and color the lane area\n",
    "    lane_clarified, left_fitx, right_fitx, ploty = color_lane_area(undist, warped_combined_binary, Minv)\n",
    "    \n",
    "    # Draw images\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(undist)\n",
    "    ax1.set_title('Undistored image , ' + fname.split('/')[-1], fontsize=50)\n",
    "    ax2.imshow(lane_clarified)\n",
    "    ax2.set_title('Lane area clarified', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "    # Save images to ./output_images\n",
    "    #fname2 = './output_images/' + 'color_bin_lane_polyfit_' + fname.split('/')[-1]\n",
    "    #cv2.imwrite(fname2, lane_poly_color)\n",
    "    #plt.imsave(fname2, lane_poly_color)\n",
    "    fname3 = './output_images/' + 'lane_clarified_' + fname.split('/')[-1]\n",
    "    #cv2.imwrite(fname3, lane_poly_combined)\n",
    "    plt.imsave(fname3, lane_clarified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Pipeline (video)\n",
    "\n",
    "#### 1. Provide a link to your final video output.  Your pipeline should perform reasonably well on the entire project video (wobbly lines are ok but no catastrophic failures that would cause the car to drive off the road!).\n",
    "\n",
    "Here's a [link to my video result](./output_images/project_video.mp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(img):\n",
    "    # Obtain undistored & warped image and matrix\n",
    "    # Undistort using mtx and dist\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    # Obtain color_binary & combined_binary\n",
    "    color_binary, combined_binary = binary_img(undist)\n",
    "    # Warpe binary images\n",
    "    #warped_color_binary = warper(color_binary)\n",
    "    warped_combined_binary, M, Minv = warper(combined_binary)\n",
    "    # Fit polynomials on lanes and color the lane area\n",
    "    lane_clarified, left_fitx, right_fitx, ploty = color_lane_area(undist, warped_combined_binary, Minv)\n",
    "    \n",
    "    return lane_clarified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_output = './output_images/project_video.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(pipeline) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(project_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"1280\" height=\"720\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(project_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_output = './output_images/challenge_video.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "white_clip = clip1.fl_image(pipeline) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"1280\" height=\"720\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harder_challenge_output = './output_images/harder_challenge_video.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"harder_challenge_video.mp4\")\n",
    "white_clip = clip1.fl_image(pipeline) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(harder_challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"1280\" height=\"720\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(harder_challenge_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Discussion\n",
    "\n",
    "#### 1. Briefly discuss any problems / issues you faced in your implementation of this project.  Where will your pipeline likely fail?  What could you do to make it more robust?\n",
    "\n",
    "Here I'll talk about the approach I took, what techniques I used, what worked and why, where the pipeline might fail and how I might improve it if I were going to pursue this project further.  \n",
    "\n",
    "1. Getting 4 points from `src` and `dst` correct in perspective transformation was the biggest challenge\n",
    "     > I took what was there as my solution. However, could not figure out how to do it myself.\n",
    "2. Getting polynomial correct mapped on lane lines.\n",
    "     > More curved harder to figure the correct polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
